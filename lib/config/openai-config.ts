// OpenAIå…¼å®¹ç«¯ç‚¹é…ç½®
export const OPENAI_API_TYPES = {
  OPENAI: 'openai',
  CUSTOM: 'custom',
  OPENROUTER: 'openrouter',
  GROQ: 'groq',
  DEEPSEEK: 'deepseek',
  AIMLAPI: 'aimlapi',
  OTHER: 'other'
} as const;

export type OpenAIApiType = typeof OPENAI_API_TYPES[keyof typeof OPENAI_API_TYPES];

// OpenAIå…¼å®¹çš„æ¨¡å‹é…ç½®
export const OPENAI_MODEL_OPTIONS = {
  // OpenAI å®˜æ–¹æ¨¡å‹
  'gpt-4o': 'GPT-4o',
  'gpt-4o-mini': 'GPT-4o Mini',
  'gpt-4-turbo': 'GPT-4 Turbo',
  'gpt-4': 'GPT-4',
  'gpt-3.5-turbo': 'GPT-3.5 Turbo',
  
  // å…¶ä»–å¸¸è§æ¨¡å‹ (ç”¨äºè‡ªå®šä¹‰ç«¯ç‚¹)
  'llama-3.1-70b-instruct': 'Llama 3.1 70B',
  'llama-3.1-8b-instruct': 'Llama 3.1 8B',
  'mixtral-8x7b-instruct': 'Mixtral 8x7B',
  'claude-3-sonnet': 'Claude 3 Sonnet',
  'deepseek-chat': 'DeepSeek Chat',
  'custom': 'è‡ªå®šä¹‰æ¨¡å‹'
} as const;

// OpenAIå…¼å®¹çš„é»˜è®¤é…ç½®
export const OPENAI_DEFAULTS = {
  apiType: OPENAI_API_TYPES.OPENAI,
  model: 'gpt-4o-mini',
  baseURL: 'https://api.openai.com/v1',
  maxTokens: 4096,
  temperature: 1.0,
  topP: 1.0,
  frequencyPenalty: 0,
  presencePenalty: 0,
  stream: true
} as const;

// é¢„å®šä¹‰çš„APIç«¯ç‚¹é…ç½®
export const PREDEFINED_ENDPOINTS = {
  [OPENAI_API_TYPES.OPENAI]: {
    name: 'OpenAI',
    baseURL: 'https://api.openai.com/v1',
    requiresApiKey: true,
    models: ['gpt-4o', 'gpt-4o-mini', 'gpt-4-turbo', 'gpt-4', 'gpt-3.5-turbo']
  },
  [OPENAI_API_TYPES.OPENROUTER]: {
    name: 'OpenRouter',
    baseURL: 'https://openrouter.ai/api/v1',
    requiresApiKey: true,
    models: ['openai/gpt-4o', 'openai/gpt-4o-mini', 'anthropic/claude-3-sonnet']
  },
  [OPENAI_API_TYPES.GROQ]: {
    name: 'Groq',
    baseURL: 'https://api.groq.com/openai/v1',
    requiresApiKey: true,
    models: ['llama-3.1-70b-versatile', 'llama-3.1-8b-instant', 'mixtral-8x7b-32768']
  },
  [OPENAI_API_TYPES.DEEPSEEK]: {
    name: 'DeepSeek',
    baseURL: 'https://api.deepseek.com/beta',
    requiresApiKey: true,
    models: ['deepseek-chat', 'deepseek-coder']
  },
  [OPENAI_API_TYPES.AIMLAPI]: {
    name: 'AI/ML API',
    baseURL: 'https://api.aimlapi.com/v1',
    requiresApiKey: true,
    models: ['gpt-4o-mini', 'gpt-4o', 'claude-3-sonnet']
  },
  [OPENAI_API_TYPES.OTHER]: {
    name: 'å…¶ä»–',
    baseURL: '',
    requiresApiKey: false,
    models: [] // å…¶ä»–ç«¯ç‚¹ä¹Ÿåº”è¯¥é€šè¿‡è¿æ¥æµ‹è¯•è·å–æ¨¡å‹åˆ—è¡¨
  },
  [OPENAI_API_TYPES.CUSTOM]: {
    name: 'è‡ªå®šä¹‰ç«¯ç‚¹',
    baseURL: '',
    requiresApiKey: false,
    models: []
  }
} as const;

// OpenAIå…¼å®¹é…ç½®æ¥å£
export interface OpenAIConfig {
  apiType: OpenAIApiType;
  baseURL: string;
  apiKey?: string;
  model: string;
  maxTokens: number;
  temperature: number;
  topP: number;
  frequencyPenalty: number;
  presencePenalty: number;
  stream: boolean;
  customHeaders?: Record<string, string>;
  customParams?: Record<string, any>;
}

// ç»Ÿä¸€çš„APIå‚æ•°æ¥å£ï¼Œæ‰©å±•ç°æœ‰çš„UnifiedApiParams
export interface OpenAIApiParams {
  model: string;
  messages: Array<{
    role: 'system' | 'user' | 'assistant';
    content: string;
  }>;
  max_tokens?: number;
  temperature?: number;
  top_p?: number;
  frequency_penalty?: number;
  presence_penalty?: number;
  stream?: boolean;
  stop?: string[];
  
  // è‡ªå®šä¹‰å‚æ•°æ”¯æŒ
  [key: string]: any;
}

// è·å–é»˜è®¤APIç±»å‹
export function getDefaultApiType(): OpenAIApiType {
  return OPENAI_DEFAULTS.apiType;
}

// è·å–é»˜è®¤æ¨¡å‹
export function getDefaultOpenAIModel(apiType: OpenAIApiType = OPENAI_DEFAULTS.apiType): string {
  const endpoint = PREDEFINED_ENDPOINTS[apiType];
  return endpoint.models[0] || OPENAI_DEFAULTS.model;
}

// æ„å»ºOpenAIé…ç½®
export function buildOpenAIConfig(userConfig: Partial<OpenAIConfig> = {}): OpenAIConfig {
  const defaults = OPENAI_DEFAULTS;
  const apiType = userConfig.apiType || defaults.apiType;
  const endpoint = PREDEFINED_ENDPOINTS[apiType];
  
  // ğŸ”¥ å¯¹äºè‡ªå®šä¹‰ç«¯ç‚¹ï¼Œå¿…é¡»æŒ‡å®šæ¨¡å‹ï¼Œä¸ä½¿ç”¨é»˜è®¤å€¼
  let model = userConfig.model;
  if (!model) {
    if (apiType === OPENAI_API_TYPES.CUSTOM) {
      // è‡ªå®šä¹‰ç«¯ç‚¹å¿…é¡»æŒ‡å®šæ¨¡å‹ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™æŠ›å‡ºé”™è¯¯
      console.warn('âš ï¸ è‡ªå®šä¹‰ç«¯ç‚¹å¿…é¡»æŒ‡å®šæ¨¡å‹åç§°');
      model = 'gpt-3.5-turbo'; // ä¸´æ—¶fallbackï¼Œé¿å…crash
    } else {
      model = getDefaultOpenAIModel(apiType);
    }
  }
  
  return {
    apiType,
    baseURL: userConfig.baseURL || endpoint.baseURL || defaults.baseURL,
    apiKey: userConfig.apiKey,
    model: model,
    maxTokens: userConfig.maxTokens ?? defaults.maxTokens,
    temperature: userConfig.temperature ?? defaults.temperature,
    topP: userConfig.topP ?? defaults.topP,
    frequencyPenalty: userConfig.frequencyPenalty ?? defaults.frequencyPenalty,
    presencePenalty: userConfig.presencePenalty ?? defaults.presencePenalty,
    stream: userConfig.stream ?? defaults.stream,
    customHeaders: userConfig.customHeaders || {},
    customParams: userConfig.customParams || {}
  };
}

// æ„å»ºOpenAI APIå‚æ•°
export function buildOpenAIApiParams(
  messages: OpenAIApiParams['messages'],
  config: OpenAIConfig
): OpenAIApiParams {
  const params: OpenAIApiParams = {
    model: config.model,
    messages,
    max_tokens: config.maxTokens,
    temperature: config.temperature,
    top_p: config.topP,
    frequency_penalty: config.frequencyPenalty,
    presence_penalty: config.presencePenalty,
    stream: config.stream,
    ...config.customParams
  };

  console.log('ğŸ”§ æ„å»ºOpenAI APIå‚æ•°:', {
    model: params.model,
    messageCount: params.messages?.length,
    stream: params.stream,
    max_tokens: params.max_tokens,
    temperature: params.temperature
  });

  // ç§»é™¤undefinedå€¼
  Object.keys(params).forEach(key => {
    if (params[key] === undefined) {
      delete params[key];
    }
  });

  return params;
}

// éªŒè¯é…ç½®
export function validateOpenAIConfig(config: OpenAIConfig): string[] {
  const errors: string[] = [];
  
  if (!config.baseURL || !config.baseURL.trim()) {
    errors.push('Base URL ä¸èƒ½ä¸ºç©º');
  }
  
  if (!config.model || !config.model.trim()) {
    errors.push('æ¨¡å‹ä¸èƒ½ä¸ºç©º');
  }
  
  const endpoint = PREDEFINED_ENDPOINTS[config.apiType];
  if (endpoint.requiresApiKey && (!config.apiKey || !config.apiKey.trim())) {
    errors.push(`${endpoint.name} éœ€è¦APIå¯†é’¥`);
  }
  
  if (config.maxTokens < 1 || config.maxTokens > 32768) {
    errors.push('æœ€å¤§ä»¤ç‰Œæ•°å¿…é¡»åœ¨ 1-32768 ä¹‹é—´');
  }
  
  if (config.temperature < 0 || config.temperature > 2) {
    errors.push('æ¸©åº¦å€¼å¿…é¡»åœ¨ 0-2 ä¹‹é—´');
  }
  
  if (config.topP < 0 || config.topP > 1) {
    errors.push('Top P å€¼å¿…é¡»åœ¨ 0-1 ä¹‹é—´');
  }
  
  return errors;
}
