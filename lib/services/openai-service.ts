// OpenAIå…¼å®¹æœåŠ¡
import { OpenAIConfig, OpenAIApiParams, buildOpenAIApiParams, OPENAI_API_TYPES } from '../config/openai-config';

export interface OpenAIStreamChunk {
  id: string;
  object: string;
  created: number;
  model: string;
  choices: Array<{
    index: number;
    delta: {
      role?: string;
      content?: string;
    };
    finish_reason: string | null;
  }>;
}

export interface OpenAIResponse {
  id: string;
  object: string;
  created: number;
  model: string;
  choices: Array<{
    index: number;
    message: {
      role: string;
      content: string;
    };
    finish_reason: string;
  }>;
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

export class OpenAIService {
  private config: OpenAIConfig;

  constructor(config: OpenAIConfig) {
    this.config = config;
  }

  // æ›´æ–°é…ç½®
  updateConfig(newConfig: OpenAIConfig) {
    this.config = newConfig;
  }

  // æ„å»ºè¯·æ±‚å¤´
  private buildHeaders(): Record<string, string> {
    const headers: Record<string, string> = {
      'Content-Type': 'application/json',
      // ğŸ”¥ æ·»åŠ åCloudflareæ£€æµ‹å¤´éƒ¨
      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
      'Accept': 'application/json, text/plain, */*',
      'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
      'Accept-Encoding': 'gzip, deflate, br',
      'Cache-Control': 'no-cache',
      'Pragma': 'no-cache',
      'Sec-CH-UA': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
      'Sec-CH-UA-Mobile': '?0',
      'Sec-CH-UA-Platform': '"Windows"',
      'Sec-Fetch-Dest': 'empty',
      'Sec-Fetch-Mode': 'cors',
      'Sec-Fetch-Site': 'cross-site'
    };

    // æ·»åŠ APIå¯†é’¥
    if (this.config.apiKey) {
      headers['Authorization'] = `Bearer ${this.config.apiKey}`;
    }

    // æ·»åŠ ç‰¹å®šAPIç±»å‹çš„å¤´éƒ¨
    switch (this.config.apiType) {
      case OPENAI_API_TYPES.OPENROUTER:
        headers['HTTP-Referer'] = typeof window !== 'undefined' ? window.location.origin : 'https://localhost:3000';
        headers['X-Title'] = 'MMG2 Chat';
        break;
      
      case OPENAI_API_TYPES.GROQ:
        // Groq ä½¿ç”¨æ ‡å‡†Bearer token
        break;
      
      case OPENAI_API_TYPES.DEEPSEEK:
        // DeepSeek ä½¿ç”¨æ ‡å‡†Bearer token
        break;
      
      case OPENAI_API_TYPES.CUSTOM:
        // è‡ªå®šä¹‰ç«¯ç‚¹æ·»åŠ Refererä»¥é¿å…CORSé—®é¢˜
        if (typeof window !== 'undefined') {
          headers['Referer'] = window.location.origin;
          headers['Origin'] = window.location.origin;
        }
        break;
    }

    // æ·»åŠ è‡ªå®šä¹‰å¤´éƒ¨ï¼ˆå¯èƒ½ä¼šè¦†ç›–ä¸Šé¢çš„é»˜è®¤å¤´éƒ¨ï¼‰
    Object.assign(headers, this.config.customHeaders);

    return headers;
  }

  // æ„å»ºè¯·æ±‚URL
  private buildUrl(): string {
    const baseURL = this.config.baseURL.replace(/\/$/, ''); // ç§»é™¤å°¾éƒ¨æ–œæ 
    return `${baseURL}/chat/completions`;
  }

  // å‘é€èŠå¤©è¯·æ±‚
  async sendChatRequest(
    messages: OpenAIApiParams['messages'],
    onProgress?: (chunk: string) => void,
    signal?: AbortSignal
  ): Promise<string | ReadableStream> {
    const params = buildOpenAIApiParams(messages, this.config);
    const headers = this.buildHeaders();
    const url = this.buildUrl();

    console.log('å‘é€OpenAIå…¼å®¹è¯·æ±‚:', {
      url,
      headers: this.sanitizeHeaders(headers),
      params: { ...params, messages: `${messages.length} messages` }
    });

    try {
      // ğŸ”¥ æ£€æµ‹æ˜¯å¦éœ€è¦ä½¿ç”¨ä»£ç†
      const urlObj = new URL(url);
      const isHttpEndpoint = urlObj.protocol === 'http:';
      
      // é¢„å®šä¹‰çš„å®˜æ–¹åŸŸåï¼Œè¿™äº›ä¸éœ€è¦ä»£ç†
      const officialDomains = [
        'api.openai.com',
        'openrouter.ai', 
        'api.groq.com',
        'api.deepseek.com',
        'api.aimlapi.com'
      ];
      
      const isOfficialDomain = officialDomains.includes(urlObj.hostname);
      const isCustomEndpoint = this.config.apiType === OPENAI_API_TYPES.CUSTOM || this.config.apiType === OPENAI_API_TYPES.OTHER;
      
      // ä½¿ç”¨ä»£ç†çš„æ¡ä»¶ï¼šHTTPåè®® æˆ– éå®˜æ–¹åŸŸå
      const shouldUseProxy = isHttpEndpoint || !isOfficialDomain;
      
      // ğŸ” è¯¦ç»†è°ƒè¯•ä¿¡æ¯
      console.log('ğŸ” [OpenAI Service] ä»£ç†æ£€æµ‹:', {
        url,
        hostname: urlObj.hostname,
        protocol: urlObj.protocol,
        apiType: this.config.apiType,
        isHttpEndpoint,
        isOfficialDomain,
        isCustomEndpoint,
        shouldUseProxy
      });
      
      let response: Response;
      
      if (shouldUseProxy && typeof window !== 'undefined') {
        // å¯¹äºHTTPç«¯ç‚¹æˆ–è‡ªå®šä¹‰ç«¯ç‚¹ï¼Œä½¿ç”¨ä»£ç†é¿å…æ··åˆå†…å®¹é”™è¯¯å’ŒCORSé—®é¢˜
        console.log(`ğŸ”„ ä½¿ç”¨ä»£ç†å‘é€èŠå¤©è¯·æ±‚ (${isHttpEndpoint ? 'HTTP' : 'CORS'}): ${url}`);
        
        const proxyResponse = await fetch('/api/proxy', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            url,
            method: 'POST',
            headers,
            body: JSON.stringify(params)
          }),
          signal
        });

        if (!proxyResponse.ok) {
          throw new Error(`ä»£ç†è¯·æ±‚å¤±è´¥: ${proxyResponse.status} ${proxyResponse.statusText}`);
        }

        const proxyData = await proxyResponse.json();
        
        if (!proxyData.success) {
          throw new Error(`èŠå¤©è¯·æ±‚å¤±è´¥: ${proxyData.error || 'ä»£ç†è¯·æ±‚å¤±è´¥'}`);
        }

        // æ¨¡æ‹ŸResponseå¯¹è±¡çš„è¡Œä¸º
        response = {
          ok: proxyData.success,
          status: proxyData.status,
          statusText: proxyData.statusText,
          json: async () => proxyData.data,
          text: async () => typeof proxyData.data === 'string' ? proxyData.data : JSON.stringify(proxyData.data),
          body: null // æ³¨æ„ï¼šä»£ç†æ¨¡å¼ä¸‹ä¸æ”¯æŒæµå¼å“åº”
        } as Response;
      } else {
        // å¯¹äºå®˜æ–¹ç«¯ç‚¹ï¼ˆOpenAIã€OpenRouterç­‰ï¼‰ï¼Œç›´æ¥è¯·æ±‚
        response = await fetch(url, {
          method: 'POST',
          headers,
          body: JSON.stringify(params),
          signal
        });
      }

      if (!response.ok) {
        const errorText = await response.text();
        let errorMessage = `è¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}`;
        
        // ğŸ”¥ æ£€æµ‹Cloudflareæ‹¦æˆª
        if (errorText.includes('<title>403 Forbidden</title>') || 
            errorText.includes('__CF$cv$params') || 
            errorText.includes('challenge-platform')) {
          errorMessage = `ğŸ›¡ï¸ Cloudflareé˜²æŠ¤æ‹¦æˆª (${response.status}): è‡ªå®šä¹‰ç«¯ç‚¹è¢«è¯†åˆ«ä¸ºæœºå™¨äººè¯·æ±‚ã€‚è¯·å°è¯•ï¼š\n` +
                        `1. æ£€æŸ¥ç«¯ç‚¹æ˜¯å¦æ”¯æŒAPIè°ƒç”¨\n` +
                        `2. è”ç³»ç«¯ç‚¹æä¾›æ–¹æ·»åŠ ç™½åå•\n` +
                        `3. å°è¯•å…¶ä»–ç«¯ç‚¹`;
        } else if (errorText.includes('<html>') && errorText.includes('<head>')) {
          // å…¶ä»–HTMLé”™è¯¯é¡µé¢
          errorMessage = `æœåŠ¡å™¨è¿”å›HTMLé¡µé¢è€ŒéAPIå“åº” (${response.status}): ç«¯ç‚¹å¯èƒ½ä¸æ”¯æŒAPIè°ƒç”¨æˆ–é…ç½®é”™è¯¯`;
        } else {
          try {
            const errorJson = JSON.parse(errorText);
            if (errorJson.error?.message) {
              errorMessage = errorJson.error.message;
            }
          } catch {
            // å¦‚æœä¸æ˜¯JSONï¼Œä½¿ç”¨åŸå§‹é”™è¯¯æ–‡æœ¬ï¼ˆæˆªå–å‰200å­—ç¬¦ï¼‰
            if (errorText) {
              errorMessage = errorText.length > 200 ? 
                `${errorText.substring(0, 200)}...` : 
                errorText;
            }
          }
        }
        
        throw new Error(errorMessage);
      }

      if (params.stream && onProgress) {
        return this.handleStreamResponse(response, onProgress);
      } else {
        return await this.handleNonStreamResponse(response);
      }
    } catch (error) {
      if (error instanceof Error && error.name === 'AbortError') {
        throw new Error('è¯·æ±‚å·²å–æ¶ˆ');
      }
      console.error('OpenAI API è¯·æ±‚é”™è¯¯:', error);
      throw error;
    }
  }

  // å¤„ç†æµå¼å“åº”
  private async handleStreamResponse(
    response: Response,
    onProgress: (chunk: string) => void
  ): Promise<string> {
    const reader = response.body?.getReader();
    if (!reader) {
      throw new Error('æ— æ³•è·å–å“åº”æµ');
    }

    const decoder = new TextDecoder();
    let fullResponse = '';

    try {
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        const chunk = decoder.decode(value, { stream: true });
        const lines = chunk.split('\n');

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = line.slice(6).trim();
            if (data === '[DONE]') {
              return fullResponse;
            }

            try {
              const parsed: OpenAIStreamChunk = JSON.parse(data);
              const content = parsed.choices[0]?.delta?.content;
              if (content) {
                fullResponse += content;
                onProgress(content);
              }
            } catch (error) {
              console.warn('è§£ææµæ•°æ®å¤±è´¥:', data, error);
            }
          }
        }
      }
    } finally {
      reader.releaseLock();
    }

    return fullResponse;
  }

  // å¤„ç†éæµå¼å“åº”
  private async handleNonStreamResponse(response: Response): Promise<string> {
    console.log('ğŸ” å¤„ç†éæµå¼å“åº”...');
    const responseText = await response.text();
    console.log('ğŸ“„ åŸå§‹å“åº”:', responseText.substring(0, 500) + (responseText.length > 500 ? '...' : ''));
    
    try {
      const data: OpenAIResponse = JSON.parse(responseText);
      console.log('ğŸ“Š è§£æåçš„æ•°æ®ç»“æ„:', {
        hasChoices: !!data.choices,
        choicesLength: data.choices?.length,
        firstChoice: data.choices?.[0] ? {
          hasMessage: !!data.choices[0].message,
          messageRole: data.choices[0].message?.role,
          hasContent: !!data.choices[0].message?.content,
          contentLength: data.choices[0].message?.content?.length
        } : null
      });
      
      const content = data.choices[0]?.message?.content || '';
      console.log('âœ… æå–çš„å†…å®¹:', content ? `"${content.substring(0, 100)}..."` : 'âŒ ç©ºå†…å®¹');
      
      if (!content) {
        console.warn('âš ï¸ éæµå¼å“åº”è¿”å›ç©ºå†…å®¹ï¼Œå®Œæ•´å“åº”:', data);
      }
      
      return content;
    } catch (error) {
      console.error('âŒ è§£æéæµå¼å“åº”å¤±è´¥:', error);
      console.log('ğŸ“„ å¤±è´¥çš„å“åº”æ–‡æœ¬:', responseText);
      throw new Error(`è§£æéæµå¼å“åº”å¤±è´¥: ${error}`);
    }
  }

  // æ¸…ç†æ•æ„Ÿä¿¡æ¯ç”¨äºæ—¥å¿—è¾“å‡º
  private sanitizeHeaders(headers: Record<string, string>): Record<string, string> {
    const sanitized = { ...headers };
    if (sanitized.Authorization) {
      sanitized.Authorization = 'Bearer [REDACTED]';
    }
    return sanitized;
  }

  // è·å–é…ç½®ä¿¡æ¯
  getConfig(): OpenAIConfig {
    return { ...this.config };
  }

  // æµ‹è¯•è¿æ¥
  async testConnection(): Promise<{ success: boolean; error?: string }> {
    try {
      const testMessages = [{ role: 'user' as const, content: 'æµ‹è¯•' }];
      await this.sendChatRequest(testMessages, undefined);
      return { success: true };
    } catch (error) {
      return {
        success: false,
        error: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'
      };
    }
  }
}

// åˆ›å»ºOpenAIæœåŠ¡å®ä¾‹çš„å·¥å‚å‡½æ•°
export function createOpenAIService(config: OpenAIConfig): OpenAIService {
  return new OpenAIService(config);
}
